{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\singvibu\\\\Desktop\\\\Github\\\\CER-classify-maps'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2 as p2\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "#from bs4 import BeautifulSoup\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# from string import digits\n",
    "# import fitz\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting The Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_word_in_str(long_str, key):\n",
    "    count = 0\n",
    "    for word in long_str.split():\n",
    "        if key in word:\n",
    "            count = count + 1\n",
    "    return(count)\n",
    "count_word_in_str(\"vibudh rocks dh dh ddh\",\"dh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_words_in_str(long_str, keys):\n",
    "    count = 0\n",
    "    for word in long_str.split():\n",
    "        for key in keys:\n",
    "            if key in word:\n",
    "                count = count + 1\n",
    "    return(count)\n",
    "count_words_in_str(\"vibudh rocks dh dh ddh\",[\"vi\", \"dh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{48: None, 49: None, 50: None, 51: None, 52: None, 53: None, 54: None, 55: None, 56: None, 57: None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'abcdefghiersuit dhfuaiwhbuitr zero'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'abc123def456ghi789ersuit834678 dhfuaiwhbui34tr234 zero0'\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "res = s.translate(remove_digits)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{48: None,\n",
       " 49: None,\n",
       " 50: None,\n",
       " 51: None,\n",
       " 52: None,\n",
       " 53: None,\n",
       " 54: None,\n",
       " 55: None,\n",
       " 56: None,\n",
       " 57: None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str.maketrans('', '', digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghiersuit dhfuaiwhbuitr zero'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'abc123def456ghi789ersuit834678 dhfuaiwhbui34tr234 zero0'\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "res = s.translate(remove_digits)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_of_imgblocks(imgblocks):\n",
    "    sum_areas = 0\n",
    "    for imgblock in imgblocks:\n",
    "        block_area = imgblock['width']* imgblock['height']\n",
    "        sum_areas = sum_areas + block_area\n",
    "    return(sum_areas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataIDs, path):\n",
    "    words_in_page = []\n",
    "    \n",
    "    scale = []\n",
    "    km_kilometers = []\n",
    "    m = []\n",
    "    metres = []\n",
    "    scale_grp = []\n",
    "    \n",
    "    legend = []\n",
    "    \n",
    "    figure = []\n",
    "    mapp = []\n",
    "    alignment_sheet = []\n",
    "    sheet = []\n",
    "    figure_grp = []\n",
    "    \n",
    "    north = []\n",
    "    n = []\n",
    "    north_grp = []\n",
    "    \n",
    "    dataID_pageNo = []\n",
    "    \n",
    "    i = 0\n",
    "    count = 0\n",
    "    \n",
    "    No_of_images = []\n",
    "    Area_of_images = []\n",
    "    cnt = 0\n",
    "    \n",
    "    page_no = []\n",
    "    error_files = []\n",
    "    \n",
    "    for dataID in dataIDs:\n",
    "        pdf_path = path + str(dataID) +'.pdf'\n",
    "        i = i+1 #Number of files\n",
    "        print(\"File Starting: {}. PDF {} out of {}\".format(dataID, i, len(dataIDs)))\n",
    "\n",
    "\n",
    "        try:\n",
    "            #if 1 == 1:\n",
    "            j = 0\n",
    "            doc = fitz.open(pdf_path)\n",
    "            \n",
    "            for page in doc:  # iterate through the pages\n",
    "                j = j+1 #Number of pages\n",
    "                cnt = cnt + 1\n",
    "                p = page.getText(\"dict\")\n",
    "            \n",
    "                blocks = p[\"blocks\"]\n",
    "                imgblocks = [b for b in blocks if b[\"type\"] == 1]\n",
    "                No_of_images.append(len(imgblocks))\n",
    "                Area_of_images.append(area_of_imgblocks(imgblocks))\n",
    "        \n",
    "        \n",
    "            \n",
    "                p = str(p).replace('<p>', '').replace('</p>','').replace(\".\",'').replace(\",\",'').replace('\"','').lower()\n",
    "                p = p.translate(remove_digits)\n",
    "                words_lst = p.split()\n",
    "                word_count = 0\n",
    "                big_words = \"\"\n",
    "                words = \"\"\n",
    "                for word in words_lst:\n",
    "                    words  = words + \" \" + word\n",
    "                    if len(word) > 3:\n",
    "                        word_count = word_count + 1\n",
    "                        big_words = big_words + \" \" + word\n",
    "                        \n",
    "                words_in_page.append(word_count)\n",
    "                \n",
    "                \n",
    "                sc_grp = 0 \n",
    "                if \"scale\" in big_words:\n",
    "                    scale.append(count_word_in_str(big_words, \"scale\"))\n",
    "                    sc_grp = 1\n",
    "                else:\n",
    "                    scale.append(0)\n",
    "                    \n",
    "                if (\"kilometre\" in big_words or \"kilometer\" in big_words or \"km \" in p):\n",
    "                    km_kilometers.append(count_words_in_str(p, [\"kilometre\", \"kilometer\", \"km \"]))\n",
    "                    sc_grp = 1\n",
    "                else:\n",
    "                    km_kilometers.append(0)\n",
    "                    \n",
    "                if(\"m \" in p):\n",
    "                    m.append(count_word_in_str(p, \"m \"))\n",
    "                else:\n",
    "                    m.append(0)\n",
    "                    \n",
    "                if(\"metre\" in big_words or \"meter\" in big_words):\n",
    "                    metres.append(count_words_in_str(big_words, [\"meter\",\"metre\"]))\n",
    "                    sc_grp = 1\n",
    "                else:\n",
    "                    metres.append(0)\n",
    "                    \n",
    "                if sc_grp > 0:\n",
    "                    scale_grp.append(1)\n",
    "                else:\n",
    "                    scale_grp.append(0)\n",
    "                    \n",
    "                \n",
    "                \n",
    "                if \"legend\" in big_words:\n",
    "                    legend.append(count_word_in_str(big_words,\"legend\"))\n",
    "                else:\n",
    "                    legend.append(0)\n",
    "                \n",
    "                    \n",
    "                    \n",
    "                fig_grp = 0\n",
    "                if \"figure\" in big_words:\n",
    "                    figure.append(count_word_in_str(big_words,\"figure\"))\n",
    "                    fig_grp = 1\n",
    "                else:\n",
    "                    figure.append(0)\n",
    "                    \n",
    "                if \"map \" in p:\n",
    "                    mapp.append(count_word_in_str(p,\"map \"))\n",
    "                    fig_grp = 1\n",
    "                else:\n",
    "                    mapp.append(0)\n",
    "                      \n",
    "                if \"alignment sheet\" in big_words:\n",
    "                    alignment_sheet.append(1)\n",
    "                    fig_grp = 1\n",
    "                else:\n",
    "                    alignment_sheet.append(0)\n",
    "                    \n",
    "                if \"sheet\" in big_words:\n",
    "                    sheet.append(count_word_in_str(big_words,\"sheet\"))\n",
    "                    fig_grp = 1\n",
    "                else:\n",
    "                    sheet.append(0)\n",
    "                \n",
    "                if fig_grp > 0:\n",
    "                    figure_grp.append(1)\n",
    "                else:\n",
    "                    figure_grp.append(0)\n",
    "                \n",
    "                \n",
    "                   \n",
    "                if \"north\" in big_words:\n",
    "                    north.append(count_word_in_str(big_words, \"north\"))\n",
    "                    no_grp = 1\n",
    "                else:\n",
    "                    north.append(0)\n",
    "                    \n",
    "                if \"n\" in p:\n",
    "                    n.append(count_word_in_str(p, \" n \"))\n",
    "                    no_grp = 1\n",
    "                else:\n",
    "                    n.append(0)\n",
    "                          \n",
    "    \n",
    "        \n",
    "                dataID_pageNo.append(str(dataID) + \"_\" + str(j))\n",
    "            page_no.append(j)\n",
    "        \n",
    "        except:\n",
    "            #if 1==0:\n",
    "            print(\"Error Found\")\n",
    "            error_files.append(dataID)\n",
    "            page_no.append(j)\n",
    "\n",
    "        \n",
    "    Features = pd.DataFrame({'scale' : scale, \n",
    "                           'km_kilometers' : km_kilometers, \n",
    "                           'm' : m, \n",
    "                           'metres' : metres, \n",
    "                           'scale_grp' : scale_grp, \n",
    "                           'legend' : legend, \n",
    "                           'figure' : figure, \n",
    "                           'mapp' : mapp, \n",
    "                           'alignment_sheet' : alignment_sheet, \n",
    "                           'sheet' : sheet, \n",
    "                           'figure_grp' : figure_grp, \n",
    "                           'north' : north, \n",
    "                           'n' : n, \n",
    "                           'words_in_page' : words_in_page,\n",
    "                            'No_of_images' : No_of_images, \n",
    "                            'Area_of_images' : Area_of_images,\n",
    "                           'dataID_pageNo' : dataID_pageNo,\n",
    "                           #'Y_class' : Y_class\n",
    "                           })\n",
    "    DataIDs = pd.DataFrame({'DataIDs': dataIDs, \n",
    "                            'Page_no': page_no})\n",
    "       \n",
    "    #print(\"Total Number of pages processed: {}\".format(count))   \n",
    "    return Features, DataIDs, error_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_pdf = \"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\RF Training Set\\\\\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Labeled Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "path_pdf = \"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\RF Training Set\\\\\"\n",
    "\n",
    "DataIDHand = [895015, 2392922, 2445549, 2967854, 2968069, 268712, \n",
    "              486221, 500633, 555093, 684494, 2758927,\n",
    "              3891802,\n",
    "             2813701, 4036098]\n",
    "Pages = [range(1,11), [1], range(1,4), [3,4],range(1,13), [3,4,5,8,9,10,14,15,24,25,26], \n",
    "         range(1,5), [5,9], [6,9,33,34], [12,13,14], [9], \n",
    "         [33, 34, 35, 89, 90, 91, 92, 93, 100, 146, 147, 148, 149, 153, 154, 159, 160, 161, 162, 165, 166, 169, 170, 173, 174, 177, 178, 181, 182, 184, 185, 188, 189], \n",
    "         [40, 92, 95, 143, 170, 180, 216, 217, 218, 219], []]\n",
    "\n",
    "print(len(DataIDHand))\n",
    "print(len(Pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fetching featuresfor the pages of the PDF Files\n",
    "# X_df, dataIDs, error_files = extract_features(DataIDHand, path_pdf) \n",
    "# #Features\n",
    "# #dataIDs\n",
    "# #error_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_df.to_csv(\"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\features_test_train.csv\")\n",
    "# dataIDs.to_csv(\"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\dataIDs.csv\")\n",
    "# print(len(error_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scale</th>\n",
       "      <th>km_kilometers</th>\n",
       "      <th>m</th>\n",
       "      <th>metres</th>\n",
       "      <th>scale_grp</th>\n",
       "      <th>legend</th>\n",
       "      <th>figure</th>\n",
       "      <th>mapp</th>\n",
       "      <th>alignment_sheet</th>\n",
       "      <th>sheet</th>\n",
       "      <th>figure_grp</th>\n",
       "      <th>north</th>\n",
       "      <th>n</th>\n",
       "      <th>words_in_page</th>\n",
       "      <th>No_of_images</th>\n",
       "      <th>Area_of_images</th>\n",
       "      <th>dataID_pageNo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15403</td>\n",
       "      <td>5</td>\n",
       "      <td>1446356</td>\n",
       "      <td>895015_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14847</td>\n",
       "      <td>5</td>\n",
       "      <td>1446356</td>\n",
       "      <td>895015_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15053</td>\n",
       "      <td>5</td>\n",
       "      <td>1446356</td>\n",
       "      <td>895015_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14210</td>\n",
       "      <td>5</td>\n",
       "      <td>1446356</td>\n",
       "      <td>895015_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14618</td>\n",
       "      <td>5</td>\n",
       "      <td>1446356</td>\n",
       "      <td>895015_5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scale  km_kilometers  m  metres  scale_grp  legend  figure  mapp  \\\n",
       "0      2              0  0       0          1       1       0     0   \n",
       "1      2              0  0       0          1       1       0     0   \n",
       "2      2              0  0       1          1       1       0     0   \n",
       "3      2              0  0       0          1       1       0     0   \n",
       "4      2              0  0       0          1       1       0     0   \n",
       "\n",
       "   alignment_sheet  sheet  figure_grp  north  n  words_in_page  No_of_images  \\\n",
       "0                1      6           1      0  0          15403             5   \n",
       "1                1      6           1      0  0          14847             5   \n",
       "2                1      6           1      0  0          15053             5   \n",
       "3                1      6           1      0  0          14210             5   \n",
       "4                1      6           1      0  0          14618             5   \n",
       "\n",
       "   Area_of_images dataID_pageNo  \n",
       "0         1446356      895015_1  \n",
       "1         1446356      895015_2  \n",
       "2         1446356      895015_3  \n",
       "3         1446356      895015_4  \n",
       "4         1446356      895015_5  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = pd.read_csv(\"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\features_test_train.csv\", index_col = 0)\n",
    "dataIDs = pd.read_csv(\"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\dataIDs.csv\", index_col = 0)\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scale</th>\n",
       "      <th>km_kilometers</th>\n",
       "      <th>m</th>\n",
       "      <th>metres</th>\n",
       "      <th>scale_grp</th>\n",
       "      <th>legend</th>\n",
       "      <th>figure</th>\n",
       "      <th>mapp</th>\n",
       "      <th>alignment_sheet</th>\n",
       "      <th>sheet</th>\n",
       "      <th>figure_grp</th>\n",
       "      <th>north</th>\n",
       "      <th>n</th>\n",
       "      <th>words_in_page</th>\n",
       "      <th>No_of_images</th>\n",
       "      <th>Area_of_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15403</td>\n",
       "      <td>5</td>\n",
       "      <td>1446356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14847</td>\n",
       "      <td>5</td>\n",
       "      <td>1446356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15053</td>\n",
       "      <td>5</td>\n",
       "      <td>1446356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14210</td>\n",
       "      <td>5</td>\n",
       "      <td>1446356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14618</td>\n",
       "      <td>5</td>\n",
       "      <td>1446356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scale  km_kilometers  m  metres  scale_grp  legend  figure  mapp  \\\n",
       "0      2              0  0       0          1       1       0     0   \n",
       "1      2              0  0       0          1       1       0     0   \n",
       "2      2              0  0       1          1       1       0     0   \n",
       "3      2              0  0       0          1       1       0     0   \n",
       "4      2              0  0       0          1       1       0     0   \n",
       "\n",
       "   alignment_sheet  sheet  figure_grp  north  n  words_in_page  No_of_images  \\\n",
       "0                1      6           1      0  0          15403             5   \n",
       "1                1      6           1      0  0          14847             5   \n",
       "2                1      6           1      0  0          15053             5   \n",
       "3                1      6           1      0  0          14210             5   \n",
       "4                1      6           1      0  0          14618             5   \n",
       "\n",
       "   Area_of_images  \n",
       "0         1446356  \n",
       "1         1446356  \n",
       "2         1446356  \n",
       "3         1446356  \n",
       "4         1446356  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df_features = X_df.copy()\n",
    "X_df_features.drop(columns=['dataID_pageNo'], inplace=True)\n",
    "X_df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Y_values(dataIDs, Pages):\n",
    "    Y_class = []\n",
    "    dataID_pageNo = []\n",
    "    j = 0\n",
    "    for index, row in dataIDs.iterrows():\n",
    "        #print(row['DataIDs'])\n",
    "        #print(row['Page_no'])\n",
    "        for i in range(1,row['Page_no']+1):\n",
    "            if i in Pages[j]:\n",
    "                Y_class.append(1)\n",
    "            else:\n",
    "                Y_class.append(0)\n",
    "            dataID_pageNo.append(str(row['DataIDs']) + \"_\" +str(i))\n",
    "        j = j+1\n",
    "    \n",
    "    Y_df = pd.DataFrame({'dataID_pageNo' : dataID_pageNo, \n",
    "                         'Y_class' : Y_class})\n",
    "    Y_dfclass = pd.DataFrame({'Y_class' : Y_class})\n",
    "    \n",
    "    return Y_df, Y_dfclass\n",
    "    \n",
    "                \n",
    "Y_df, Y_dfclass = get_Y_values(dataIDs, Pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "994\n",
      "994\n",
      "994\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_df))\n",
    "print(len(X_df))\n",
    "print(len(Y_dfclass))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data for Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(745, 16)\n",
      "(249, 16)\n",
      "(745, 1)\n",
      "(249, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df_features,\n",
    "                                                    Y_dfclass,\n",
    "                                                    test_size = 0.25,\n",
    "                                                    random_state = 8)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set:  745\n",
      "Alignment Sheets in Training Set:  68\n",
      "\n",
      "Test Set:  249\n",
      "Alignment Sheets in Training Set:  28\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set: \", len(y_train))\n",
    "print(\"Alignment Sheets in Training Set: \", len(y_train[y_train.Y_class > 0]))\n",
    "print()\n",
    "print(\"Test Set: \", len(y_test))\n",
    "print(\"Alignment Sheets in Training Set: \", len(y_test[y_test.Y_class > 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(19)\n",
    "\n",
    "classifiers = []\n",
    "name = []\n",
    "# we will create an array of Classifiers and append different classification models to our array.\n",
    "model1 = xgboost.XGBClassifier()\n",
    "classifiers.append(model1)\n",
    "name.append(\"xgboost\")\n",
    "\n",
    "model2 = svm.SVC()\n",
    "classifiers.append(model2)\n",
    "name.append(\"svc\")\n",
    "\n",
    "model3 = tree.DecisionTreeClassifier()\n",
    "classifiers.append(model3)\n",
    "name.append(\"decisiontree\")\n",
    "\n",
    "model4 = RandomForestClassifier()\n",
    "classifiers.append(model4)\n",
    "name.append(\"rfc\")\n",
    "\n",
    "\n",
    "model5 = RandomForestRegressor(n_estimators=5)\n",
    "classifiers.append(model5)\n",
    "name.append(\"rfr5\")\n",
    "\n",
    "model6 = RandomForestRegressor(n_estimators=25)\n",
    "classifiers.append(model6)\n",
    "name.append(\"rfr25\")\n",
    "\n",
    "model7 = RandomForestRegressor(n_estimators=50)\n",
    "classifiers.append(model7)\n",
    "name.append(\"rfr50\")\n",
    "\n",
    "model8 = RandomForestRegressor(n_estimators=75)\n",
    "classifiers.append(model8)\n",
    "name.append(\"rfr75\")\n",
    "\n",
    "model9 = RandomForestRegressor(n_estimators=100)\n",
    "classifiers.append(model9)\n",
    "name.append(\"rfr100\")\n",
    "\n",
    "\n",
    "model10 = XGBRegressor(n_estimators=5)\n",
    "classifiers.append(model10)\n",
    "name.append(\"xgbr5\")\n",
    "\n",
    "model11 = XGBRegressor(n_estimators=25)\n",
    "classifiers.append(model11)\n",
    "name.append(\"xgbr25\")\n",
    "\n",
    "model12 = XGBRegressor(n_estimators=50)\n",
    "classifiers.append(model12)\n",
    "name.append(\"xgbr50\")\n",
    "\n",
    "model13 = XGBRegressor(n_estimators=75)\n",
    "classifiers.append(model13)\n",
    "name.append(\"xgbr75\")\n",
    "\n",
    "model14 = XGBRegressor(n_estimators=100)\n",
    "classifiers.append(model14)\n",
    "name.append(\"xgbr100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "________________________________________________________\n",
      "[04:05:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "xgboost\n",
      "Accuracy of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None) is 0.9919678714859438\n",
      "Confusion Matrix of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None) is [[221   0]\n",
      " [  2  26]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "svc\n",
      "Accuracy of SVC() is 0.9236947791164659\n",
      "Confusion Matrix of SVC() is [[221   0]\n",
      " [ 19   9]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "decisiontree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of DecisionTreeClassifier() is 0.9879518072289156\n",
      "Confusion Matrix of DecisionTreeClassifier() is [[220   1]\n",
      " [  2  26]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "rfc\n",
      "Accuracy of RandomForestClassifier() is 0.9919678714859438\n",
      "Confusion Matrix of RandomForestClassifier() is [[221   0]\n",
      " [  2  26]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "rfr5\n",
      "Accuracy of RandomForestRegressor(n_estimators=5) is 0.9879518072289156\n",
      "Confusion Matrix of RandomForestRegressor(n_estimators=5) is [[220   1]\n",
      " [  2  26]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "rfr25\n",
      "Accuracy of RandomForestRegressor(n_estimators=25) is 0.9919678714859438\n",
      "Confusion Matrix of RandomForestRegressor(n_estimators=25) is [[221   0]\n",
      " [  2  26]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-beb164b32588>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n",
      "<ipython-input-18-beb164b32588>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n",
      "<ipython-input-18-beb164b32588>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n",
      "<ipython-input-18-beb164b32588>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfr50\n",
      "Accuracy of RandomForestRegressor(n_estimators=50) is 0.9919678714859438\n",
      "Confusion Matrix of RandomForestRegressor(n_estimators=50) is [[221   0]\n",
      " [  2  26]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "rfr75\n",
      "Accuracy of RandomForestRegressor(n_estimators=75) is 0.9919678714859438\n",
      "Confusion Matrix of RandomForestRegressor(n_estimators=75) is [[221   0]\n",
      " [  2  26]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "rfr100\n",
      "Accuracy of RandomForestRegressor() is 0.9919678714859438\n",
      "Confusion Matrix of RandomForestRegressor() is [[221   0]\n",
      " [  2  26]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "xgbr5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-beb164b32588>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n",
      "<ipython-input-18-beb164b32588>:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=5, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9879518072289156\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=5, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[220   1]\n",
      " [  2  26]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "xgbr25\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=25, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9879518072289156\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=25, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[220   1]\n",
      " [  2  26]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "xgbr50\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=50, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9879518072289156\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=50, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[220   1]\n",
      " [  2  26]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "xgbr75\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=75, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9879518072289156\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=75, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[220   1]\n",
      " [  2  26]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "xgbr100\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=100, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9879518072289156\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=100, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[220   1]\n",
      " [  2  26]]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "random.seed(10)\n",
    "test_accuracy = []\n",
    "for clf in classifiers:\n",
    "    print(\"________________________________________________________\")\n",
    "    print(\"________________________________________________________\")\n",
    "    #fit our algorithms in our Train dataset \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    #get test dataset prediction\n",
    "    if \"rfr\" or \"xgbr\" in name[i]:\n",
    "        y_pred_nb = clf.predict(X_test)\n",
    "        #y_pred.shape\n",
    "        #y_pred\n",
    "        y_pred = []\n",
    "        for y in y_pred_nb:\n",
    "            if y > 0.50:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "    else:\n",
    "        y_pred= clf.predict(X_test)\n",
    "        \n",
    "    print(name[i])\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    test_accuracy.append(acc)\n",
    "    print(\"Accuracy of %s is %s\"%(clf, acc))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix of %s is %s\"%(clf, cm))\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "DataIDHand = [3410189, 3970828, 2968356]\n",
    "Pages = [[], \n",
    "         [29, 35, 51, 59, 100, 101, 108, 109, 165, 179, 225, 231, 293, 294], \n",
    "         [9,18, 26]]\n",
    "\n",
    "print(len(DataIDHand))\n",
    "print(len(Pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_pdf = \"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\RF Validation Set\\\\\"\n",
    "\n",
    "# # #fetching featuresfor the pages of the PDF Files\n",
    "# X_df_valid, dataIDs_valid, error_files = extract_features(DataIDHand, path_pdf) \n",
    "# # #Features\n",
    "# # #dataIDs\n",
    "# # #error_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_df_valid.to_csv(\"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\features_valid.csv\")\n",
    "# dataIDs_valid.to_csv(\"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\dataIDs_valid.csv\")\n",
    "# print(len(error_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scale</th>\n",
       "      <th>km_kilometers</th>\n",
       "      <th>m</th>\n",
       "      <th>metres</th>\n",
       "      <th>scale_grp</th>\n",
       "      <th>legend</th>\n",
       "      <th>figure</th>\n",
       "      <th>mapp</th>\n",
       "      <th>alignment_sheet</th>\n",
       "      <th>sheet</th>\n",
       "      <th>figure_grp</th>\n",
       "      <th>north</th>\n",
       "      <th>n</th>\n",
       "      <th>words_in_page</th>\n",
       "      <th>No_of_images</th>\n",
       "      <th>Area_of_images</th>\n",
       "      <th>dataID_pageNo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3410189_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3970828_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3970828_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3970828_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3970828_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scale  km_kilometers  m  metres  scale_grp  legend  figure  mapp  \\\n",
       "0      0              0  0       0          0       0       0     0   \n",
       "1      0              0  0       0          0       0       0     0   \n",
       "2      0              0  0       0          0       0       0     0   \n",
       "3      0              0  0       0          0       0       0     0   \n",
       "4      0              0  0       0          0       0       0     0   \n",
       "\n",
       "   alignment_sheet  sheet  figure_grp  north  n  words_in_page  No_of_images  \\\n",
       "0                0      0           0      0  0            642             0   \n",
       "1                0      0           0      0  0            173             0   \n",
       "2                0      0           0      0  0             92             0   \n",
       "3                0      0           0      0  0            234             0   \n",
       "4                0      0           0      0  0             92             0   \n",
       "\n",
       "   Area_of_images dataID_pageNo  \n",
       "0               0     3410189_1  \n",
       "1               0     3970828_1  \n",
       "2               0     3970828_2  \n",
       "3               0     3970828_3  \n",
       "4               0     3970828_4  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df_valid = pd.read_csv(\"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\features_valid.csv\", index_col = 0)\n",
    "dataIDs_valid = pd.read_csv(\"C:\\\\Users\\\\singvibu\\\\Desktop\\\\GIS Location Extraction\\\\dataIDs_valid.csv\", index_col = 0)\n",
    "X_df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scale</th>\n",
       "      <th>km_kilometers</th>\n",
       "      <th>m</th>\n",
       "      <th>metres</th>\n",
       "      <th>scale_grp</th>\n",
       "      <th>legend</th>\n",
       "      <th>figure</th>\n",
       "      <th>mapp</th>\n",
       "      <th>alignment_sheet</th>\n",
       "      <th>sheet</th>\n",
       "      <th>figure_grp</th>\n",
       "      <th>north</th>\n",
       "      <th>n</th>\n",
       "      <th>words_in_page</th>\n",
       "      <th>No_of_images</th>\n",
       "      <th>Area_of_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>642</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scale  km_kilometers  m  metres  scale_grp  legend  figure  mapp  \\\n",
       "0      0              0  0       0          0       0       0     0   \n",
       "1      0              0  0       0          0       0       0     0   \n",
       "2      0              0  0       0          0       0       0     0   \n",
       "3      0              0  0       0          0       0       0     0   \n",
       "4      0              0  0       0          0       0       0     0   \n",
       "\n",
       "   alignment_sheet  sheet  figure_grp  north  n  words_in_page  No_of_images  \\\n",
       "0                0      0           0      0  0            642             0   \n",
       "1                0      0           0      0  0            173             0   \n",
       "2                0      0           0      0  0             92             0   \n",
       "3                0      0           0      0  0            234             0   \n",
       "4                0      0           0      0  0             92             0   \n",
       "\n",
       "   Area_of_images  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df_features_valid = X_df_valid.copy()\n",
    "X_df_features_valid.drop(columns=['dataID_pageNo'], inplace=True)\n",
    "X_df_features_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "555\n",
      "555\n",
      "555\n",
      "555\n"
     ]
    }
   ],
   "source": [
    "Y_df_valid, Y_dfclass_valid = get_Y_values(dataIDs_valid, Pages)\n",
    "\n",
    "print(len(Y_df_valid))\n",
    "print(len(X_df_features_valid))\n",
    "print(len(X_df_valid))\n",
    "print(len(Y_dfclass_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________\n",
      "________________________________________________________\n",
      "[04:05:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "xgboost\n",
      "Accuracy of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None) is 0.9919678714859438\n",
      "Confusion Matrix of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None) is [[221   0]\n",
      " [  2  26]]\n",
      "________________Validation Set ___________________________\n",
      "xgboost\n",
      "Accuracy of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None) is 0.990990990990991\n",
      "Confusion Matrix of XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "              tree_method='exact', validate_parameters=1, verbosity=None) is [[533   5]\n",
      " [  0  17]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "svc\n",
      "Accuracy of SVC() is 0.9236947791164659\n",
      "Confusion Matrix of SVC() is [[221   0]\n",
      " [ 19   9]]\n",
      "________________Validation Set ___________________________\n",
      "svc\n",
      "Accuracy of SVC() is 0.9693693693693693\n",
      "Confusion Matrix of SVC() is [[538   0]\n",
      " [ 17   0]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "decisiontree\n",
      "Accuracy of DecisionTreeClassifier() is 0.9879518072289156\n",
      "Confusion Matrix of DecisionTreeClassifier() is [[220   1]\n",
      " [  2  26]]\n",
      "________________Validation Set ___________________________\n",
      "decisiontree\n",
      "Accuracy of DecisionTreeClassifier() is 0.9837837837837838\n",
      "Confusion Matrix of DecisionTreeClassifier() is [[529   9]\n",
      " [  0  17]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "<ipython-input-25-77b733f36b10>:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc\n",
      "Accuracy of RandomForestClassifier() is 0.9919678714859438\n",
      "Confusion Matrix of RandomForestClassifier() is [[221   0]\n",
      " [  2  26]]\n",
      "________________Validation Set ___________________________\n",
      "rfc\n",
      "Accuracy of RandomForestClassifier() is 0.9963963963963964\n",
      "Confusion Matrix of RandomForestClassifier() is [[536   2]\n",
      " [  0  17]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "rfr5\n",
      "Accuracy of RandomForestRegressor(n_estimators=5) is 0.9919678714859438\n",
      "Confusion Matrix of RandomForestRegressor(n_estimators=5) is [[221   0]\n",
      " [  2  26]]\n",
      "________________Validation Set ___________________________\n",
      "rfr5\n",
      "Accuracy of RandomForestRegressor(n_estimators=5) is 0.963963963963964\n",
      "Confusion Matrix of RandomForestRegressor(n_estimators=5) is [[519  19]\n",
      " [  1  16]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "rfr25\n",
      "Accuracy of RandomForestRegressor(n_estimators=25) is 0.9919678714859438\n",
      "Confusion Matrix of RandomForestRegressor(n_estimators=25) is [[221   0]\n",
      " [  2  26]]\n",
      "________________Validation Set ___________________________\n",
      "rfr25\n",
      "Accuracy of RandomForestRegressor(n_estimators=25) is 0.963963963963964\n",
      "Confusion Matrix of RandomForestRegressor(n_estimators=25) is [[519  19]\n",
      " [  1  16]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "rfr50\n",
      "Accuracy of RandomForestRegressor(n_estimators=50) is 0.9919678714859438\n",
      "Confusion Matrix of RandomForestRegressor(n_estimators=50) is [[221   0]\n",
      " [  2  26]]\n",
      "________________Validation Set ___________________________\n",
      "rfr50\n",
      "Accuracy of RandomForestRegressor(n_estimators=50) is 0.9873873873873874\n",
      "Confusion Matrix of RandomForestRegressor(n_estimators=50) is [[531   7]\n",
      " [  0  17]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "rfr75\n",
      "Accuracy of RandomForestRegressor(n_estimators=75) is 0.9919678714859438\n",
      "Confusion Matrix of RandomForestRegressor(n_estimators=75) is [[221   0]\n",
      " [  2  26]]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-77b733f36b10>:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n",
      "<ipython-input-25-77b733f36b10>:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n",
      "<ipython-input-25-77b733f36b10>:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n",
      "<ipython-input-25-77b733f36b10>:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "________________Validation Set ___________________________\n",
      "rfr75\n",
      "Accuracy of RandomForestRegressor(n_estimators=75) is 0.9657657657657658\n",
      "Confusion Matrix of RandomForestRegressor(n_estimators=75) is [[520  18]\n",
      " [  1  16]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "rfr100\n",
      "Accuracy of RandomForestRegressor() is 0.9919678714859438\n",
      "Confusion Matrix of RandomForestRegressor() is [[221   0]\n",
      " [  2  26]]\n",
      "________________Validation Set ___________________________\n",
      "rfr100\n",
      "Accuracy of RandomForestRegressor() is 0.9819819819819819\n",
      "Confusion Matrix of RandomForestRegressor() is [[529   9]\n",
      " [  1  16]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "xgbr5\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=5, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9879518072289156\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=5, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[220   1]\n",
      " [  2  26]]\n",
      "________________Validation Set ___________________________\n",
      "xgbr5\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=5, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9819819819819819\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=5, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[528  10]\n",
      " [  0  17]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "xgbr25\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=25, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9879518072289156\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=25, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[220   1]\n",
      " [  2  26]]\n",
      "________________Validation Set ___________________________\n",
      "xgbr25\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=25, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9819819819819819\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=25, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[528  10]\n",
      " [  0  17]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "xgbr50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-77b733f36b10>:11: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=50, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9879518072289156\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=50, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[220   1]\n",
      " [  2  26]]\n",
      "________________Validation Set ___________________________\n",
      "xgbr50\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=50, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9819819819819819\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=50, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[528  10]\n",
      " [  0  17]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "xgbr75\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=75, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9879518072289156\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=75, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[220   1]\n",
      " [  2  26]]\n",
      "________________Validation Set ___________________________\n",
      "xgbr75\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=75, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9819819819819819\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=75, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[528  10]\n",
      " [  0  17]]\n",
      "________________________________________________________\n",
      "________________________________________________________\n",
      "xgbr100\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=100, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9879518072289156\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=100, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[220   1]\n",
      " [  2  26]]\n",
      "________________Validation Set ___________________________\n",
      "xgbr100\n",
      "Accuracy of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=100, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is 0.9819819819819819\n",
      "Confusion Matrix of XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "             importance_type='gain', interaction_constraints='',\n",
      "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
      "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "             n_estimators=100, n_jobs=16, num_parallel_tree=1, random_state=0,\n",
      "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
      "             tree_method='exact', validate_parameters=1, verbosity=None) is [[528  10]\n",
      " [  0  17]]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "random.seed(10)\n",
    "test_accuracy = []\n",
    "valid_accuracy = []\n",
    "cm_test = []\n",
    "cm_valid = []\n",
    "for clf in classifiers:\n",
    "    print(\"________________________________________________________\")\n",
    "    print(\"________________________________________________________\")\n",
    "    #fit our algorithms in our Train dataset \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    #get test dataset prediction\n",
    "    if \"rfr\" or \"xgbr\" in name[i]:\n",
    "        y_pred_nb = clf.predict(X_test)\n",
    "        #y_pred.shape\n",
    "        #y_pred\n",
    "        y_pred = []\n",
    "        for y in y_pred_nb:\n",
    "            if y > 0.50:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "    else:\n",
    "        y_pred= clf.predict(X_test)\n",
    "        \n",
    "    print(name[i])\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    test_accuracy.append(acc)\n",
    "    print(\"Accuracy of %s is %s\"%(clf, acc))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix of %s is %s\"%(clf, cm))\n",
    "    cm_test.append(cm)\n",
    "    \n",
    "    \n",
    "    print(\"________________Validation Set ___________________________\")\n",
    "    #get validation accuracy\n",
    "    if \"rfr\" or \"xgbr\" in name[i]:\n",
    "        y_pred_nb = clf.predict(X_df_features_valid)\n",
    "        #y_pred.shape\n",
    "        #y_pred\n",
    "        y_pred = []\n",
    "        for y in y_pred_nb:\n",
    "            if y > 0.50:\n",
    "                y_pred.append(1)\n",
    "            else:\n",
    "                y_pred.append(0)\n",
    "    else:\n",
    "        y_pred= clf.predict(X_df_features_valid)\n",
    "        \n",
    "    print(name[i])\n",
    "    acc = accuracy_score(Y_dfclass_valid[\"Y_class\"], y_pred)\n",
    "    valid_accuracy.append(acc)\n",
    "    print(\"Accuracy of %s is %s\"%(clf, acc))\n",
    "    cm = confusion_matrix(Y_dfclass_valid[\"Y_class\"], y_pred)\n",
    "    print(\"Confusion Matrix of %s is %s\"%(clf, cm))\n",
    "    cm_valid.append(cm)\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_cm</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>valid_cm</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svc</td>\n",
       "      <td>0.923695</td>\n",
       "      <td>[[221, 0], [19, 9]]</td>\n",
       "      <td>0.969369</td>\n",
       "      <td>[[538, 0], [17, 0]]</td>\n",
       "      <td>0.895401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rfr5</td>\n",
       "      <td>0.991968</td>\n",
       "      <td>[[221, 0], [2, 26]]</td>\n",
       "      <td>0.963964</td>\n",
       "      <td>[[519, 19], [1, 16]]</td>\n",
       "      <td>0.956221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfr25</td>\n",
       "      <td>0.991968</td>\n",
       "      <td>[[221, 0], [2, 26]]</td>\n",
       "      <td>0.963964</td>\n",
       "      <td>[[519, 19], [1, 16]]</td>\n",
       "      <td>0.956221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rfr75</td>\n",
       "      <td>0.991968</td>\n",
       "      <td>[[221, 0], [2, 26]]</td>\n",
       "      <td>0.965766</td>\n",
       "      <td>[[520, 18], [1, 16]]</td>\n",
       "      <td>0.958009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xgbr5</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>[[220, 1], [2, 26]]</td>\n",
       "      <td>0.981982</td>\n",
       "      <td>[[528, 10], [0, 17]]</td>\n",
       "      <td>0.970151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>xgbr25</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>[[220, 1], [2, 26]]</td>\n",
       "      <td>0.981982</td>\n",
       "      <td>[[528, 10], [0, 17]]</td>\n",
       "      <td>0.970151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xgbr50</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>[[220, 1], [2, 26]]</td>\n",
       "      <td>0.981982</td>\n",
       "      <td>[[528, 10], [0, 17]]</td>\n",
       "      <td>0.970151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xgbr75</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>[[220, 1], [2, 26]]</td>\n",
       "      <td>0.981982</td>\n",
       "      <td>[[528, 10], [0, 17]]</td>\n",
       "      <td>0.970151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xgbr100</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>[[220, 1], [2, 26]]</td>\n",
       "      <td>0.981982</td>\n",
       "      <td>[[528, 10], [0, 17]]</td>\n",
       "      <td>0.970151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>decisiontree</td>\n",
       "      <td>0.987952</td>\n",
       "      <td>[[220, 1], [2, 26]]</td>\n",
       "      <td>0.983784</td>\n",
       "      <td>[[529, 9], [0, 17]]</td>\n",
       "      <td>0.971931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rfr100</td>\n",
       "      <td>0.991968</td>\n",
       "      <td>[[221, 0], [2, 26]]</td>\n",
       "      <td>0.981982</td>\n",
       "      <td>[[529, 9], [1, 16]]</td>\n",
       "      <td>0.974095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rfr50</td>\n",
       "      <td>0.991968</td>\n",
       "      <td>[[221, 0], [2, 26]]</td>\n",
       "      <td>0.987387</td>\n",
       "      <td>[[531, 7], [0, 17]]</td>\n",
       "      <td>0.979457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.991968</td>\n",
       "      <td>[[221, 0], [2, 26]]</td>\n",
       "      <td>0.990991</td>\n",
       "      <td>[[533, 5], [0, 17]]</td>\n",
       "      <td>0.983031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rfc</td>\n",
       "      <td>0.991968</td>\n",
       "      <td>[[221, 0], [2, 26]]</td>\n",
       "      <td>0.996396</td>\n",
       "      <td>[[536, 2], [0, 17]]</td>\n",
       "      <td>0.988393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name  test_accuracy              test_cm  valid_accuracy  \\\n",
       "1            svc       0.923695  [[221, 0], [19, 9]]        0.969369   \n",
       "4           rfr5       0.991968  [[221, 0], [2, 26]]        0.963964   \n",
       "5          rfr25       0.991968  [[221, 0], [2, 26]]        0.963964   \n",
       "7          rfr75       0.991968  [[221, 0], [2, 26]]        0.965766   \n",
       "9          xgbr5       0.987952  [[220, 1], [2, 26]]        0.981982   \n",
       "10        xgbr25       0.987952  [[220, 1], [2, 26]]        0.981982   \n",
       "11        xgbr50       0.987952  [[220, 1], [2, 26]]        0.981982   \n",
       "12        xgbr75       0.987952  [[220, 1], [2, 26]]        0.981982   \n",
       "13       xgbr100       0.987952  [[220, 1], [2, 26]]        0.981982   \n",
       "2   decisiontree       0.987952  [[220, 1], [2, 26]]        0.983784   \n",
       "8         rfr100       0.991968  [[221, 0], [2, 26]]        0.981982   \n",
       "6          rfr50       0.991968  [[221, 0], [2, 26]]        0.987387   \n",
       "0        xgboost       0.991968  [[221, 0], [2, 26]]        0.990991   \n",
       "3            rfc       0.991968  [[221, 0], [2, 26]]        0.996396   \n",
       "\n",
       "                valid_cm   product  \n",
       "1    [[538, 0], [17, 0]]  0.895401  \n",
       "4   [[519, 19], [1, 16]]  0.956221  \n",
       "5   [[519, 19], [1, 16]]  0.956221  \n",
       "7   [[520, 18], [1, 16]]  0.958009  \n",
       "9   [[528, 10], [0, 17]]  0.970151  \n",
       "10  [[528, 10], [0, 17]]  0.970151  \n",
       "11  [[528, 10], [0, 17]]  0.970151  \n",
       "12  [[528, 10], [0, 17]]  0.970151  \n",
       "13  [[528, 10], [0, 17]]  0.970151  \n",
       "2    [[529, 9], [0, 17]]  0.971931  \n",
       "8    [[529, 9], [1, 16]]  0.974095  \n",
       "6    [[531, 7], [0, 17]]  0.979457  \n",
       "0    [[533, 5], [0, 17]]  0.983031  \n",
       "3    [[536, 2], [0, 17]]  0.988393  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_models = pd.DataFrame({'name': name, \n",
    "                                     'test_accuracy': test_accuracy,\n",
    "                                     'test_cm': cm_test, \n",
    "                                     'valid_accuracy':valid_accuracy,\n",
    "                                     'valid_cm': cm_valid})\n",
    "classification_models[\"product\"] = classification_models[\"test_accuracy\"]*classification_models[\"valid_accuracy\"]\n",
    "\n",
    "classification_models = classification_models.sort_values(by=['product'])\n",
    "classification_models.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rfc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-1ca5fb039fab>:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_train, y_train)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "random.seed(10)\n",
    "\n",
    "for clf in classifiers:\n",
    "    \n",
    "    if name[i] != \"rfc\":\n",
    "        i = i +1\n",
    "        continue\n",
    "    print(name[i])\n",
    "    clf.fit(X_train, y_train)\n",
    "    filename = \"G:\\\\ESA_downloads\\\\Demo_Alignment_Sheets\\\\alignment_sheet_classifier_rfc.sav\"\n",
    "    pickle.dump(clf, open(filename, 'wb'))\n",
    "    \n",
    "    filename = \"alignment_sheet_classifier_rfr50.sav\"\n",
    "    pickle.dump(clf, open(filename, 'wb'))\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=50, random_state=0)\n",
    "#n_estimators - Number of trees in the forest \n",
    "#random_state - Controls both the randomness of the bootstrapping of the samples used when building \n",
    "              # trees (if bootstrap=True) and the sampling of the features to consider when looking \n",
    "              # for the best split at each node (if max_features < n_features)\n",
    "# Ref -> https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "\n",
    "\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "file_name =  \"alignment_sheet_classifier_rfr.sav\"\n",
    "pickle.dump(regressor, open(file_name, 'wb'))\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "#y_pred.shape\n",
    "#y_pred\n",
    "y_predict = []\n",
    "for y in y_pred:\n",
    "    if y > 0.40:\n",
    "        y_predict.append(1)\n",
    "    else:\n",
    "        y_predict.append(0)\n",
    "#y_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_importance = regressor.feature_importances_\n",
    "feature = []\n",
    "\n",
    "for col in X_df_features:\n",
    "    feature.append(col)\n",
    "    \n",
    "df_f_importance = pd.DataFrame({'Feature_Name' :  feature, \n",
    "                                'Importance':  f_importance})\n",
    "df_f_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackabuse.com/random-forest-algorithm-with-python-and-scikit-learn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[178   0]\n",
      " [  0  21]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       178\n",
      "           1       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           1.00       199\n",
      "   macro avg       1.00      1.00      1.00       199\n",
      "weighted avg       1.00      1.00      1.00       199\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(classification_report(y_test,y_predict))\n",
    "print(accuracy_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-23dedec02bfc>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  XYRdf_dataset['Y_test'] = y_test\n",
      "<ipython-input-18-23dedec02bfc>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  XYRdf_dataset['y_score'] = y_pred\n",
      "<ipython-input-18-23dedec02bfc>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  XYRdf_dataset['y_predict'] = y_predict\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scale</th>\n",
       "      <th>km_kilometers</th>\n",
       "      <th>m</th>\n",
       "      <th>metres</th>\n",
       "      <th>scale_grp</th>\n",
       "      <th>legend</th>\n",
       "      <th>figure</th>\n",
       "      <th>mapp</th>\n",
       "      <th>alignment_sheet</th>\n",
       "      <th>sheet</th>\n",
       "      <th>figure_grp</th>\n",
       "      <th>north</th>\n",
       "      <th>n</th>\n",
       "      <th>words_in_page</th>\n",
       "      <th>No_of_images</th>\n",
       "      <th>Area_of_images</th>\n",
       "      <th>Y_test</th>\n",
       "      <th>y_score</th>\n",
       "      <th>y_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1226</td>\n",
       "      <td>2</td>\n",
       "      <td>24772</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>841</td>\n",
       "      <td>2</td>\n",
       "      <td>24423</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5062</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1054</td>\n",
       "      <td>1</td>\n",
       "      <td>21293520</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     scale  km_kilometers  m  metres  scale_grp  legend  figure  mapp  \\\n",
       "643      0              0  0       7          1       0       0     0   \n",
       "41       0              0  0       0          0       0       0     0   \n",
       "730      1              0  0       0          1       0       0     0   \n",
       "100      0              0  0       0          0       0       0     0   \n",
       "604      0              0  0       0          0       0       1     0   \n",
       "\n",
       "     alignment_sheet  sheet  figure_grp  north  n  words_in_page  \\\n",
       "643                0      0           0      2  0           1226   \n",
       "41                 0      0           0      0  0           1354   \n",
       "730                0      0           0      0  0            841   \n",
       "100                0      0           0      1  0           5062   \n",
       "604                0      0           1      0  0           1054   \n",
       "\n",
       "     No_of_images  Area_of_images  Y_test  y_score  y_predict  \n",
       "643             2           24772       0      0.0          0  \n",
       "41              0               0       0      0.0          0  \n",
       "730             2           24423       0      0.0          0  \n",
       "100             0               0       0      0.0          0  \n",
       "604             1        21293520       1      1.0          1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XYRdf_dataset = X_test\n",
    "XYRdf_dataset['Y_test'] = y_test\n",
    "XYRdf_dataset['y_score'] = y_pred\n",
    "XYRdf_dataset['y_predict'] = y_predict\n",
    "#XYRdf_dataset['dataID_pageNo' : dataID_pageNo]\n",
    "len(XYRdf_dataset)\n",
    "XYRdf_dataset.head()\n",
    "\n",
    "\n",
    "XYRdf_dataset.to_csv(path_pdf + \"Results_Training_Set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
